{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jaejinan/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from numpy import linalg as LA\n",
    "import librosa\n",
    "import keras\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D,MaxPooling1D,Conv2D,MaxPooling2D,Dense,Flatten,Dropout\n",
    "from keras import backend as K\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import time\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import random\n",
    "#from pylab import *\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading models and calling parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_exam = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json, model_from_yaml\n",
    "#Calling models saved in JSON format\n",
    "json_string = open('./sound5.json', 'r').read()\n",
    "model_exam = model_from_json(json_string)\n",
    "model_exam.load_weights('./sound5.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD, Adadelta, Adam, RMSprop\n",
    "\n",
    "model_exam.compile(loss=\"categorical_crossentropy\", # 誤差(損失)関数\n",
    "             optimizer=\"adam\", # 最適化関数\n",
    "             metrics=[\"accuracy\"] # 評価指標\n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load row datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['疲弊LV-4', '疲弊LV-3', '疲弊LV-2', '疲弊LV-0', '疲弊LV-1']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(\"./BillData/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['wavedata_S03DF_6', 'image']\n"
     ]
    }
   ],
   "source": [
    "data_arr = []\n",
    "levels=os.listdir(\"./exam/\")\n",
    "for a in levels:\n",
    "    try:\n",
    "        if (not a.startswith('.') and not a.startswith('i')):\n",
    "            num_arr = []\n",
    "            path_to_file = os.path.join(\"./exam/\"+a)\n",
    "            fd = open(path_to_file , 'r')\n",
    "            while True:\n",
    "                string = fd.readline()\n",
    "                if not string: break\n",
    "                data_arr.append(float(string[:-1]))\n",
    "            fd.close()\n",
    "    except AttributeError:\n",
    "        print(\"\")\n",
    "        \n",
    "#data_arr[level_num][file_num][numbers]\n",
    "#level_num : 0~4(5 classes)\n",
    "#file_num : 0~79(20*4 files)\n",
    "#numbers : 0~8799(8800 amplitudes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Datas=np.array(data_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Division5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in range(0,5):\n",
    "    fig = plt.figure()\n",
    "    plt.plot(Datas[550*c:550*c+6599],antialiased=False,color='black',linewidth=0.5)\n",
    "    plt.axis([0,6600,-1,1])\n",
    "    plt.tick_params(labelbottom=False,labelleft=False,labelright=False,labeltop=False)\n",
    "    plt.tick_params(bottom=False,left=False,right=False,top=False)\n",
    "    plt.box(False)\n",
    "    plt.subplots_adjust(left=0,right=1,bottom=0,top=1)\n",
    "    plt.savefig('./exam/image/'+str(c+1)+'.png')\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and save images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.png\n",
      "5.png\n",
      "2.png\n",
      "3.png\n",
      "1.png\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "levels=os.listdir(\"./exam/image\")\n",
    "for a in levels:\n",
    "    try:\n",
    "        if not a.startswith('.'):\n",
    "            print(a)\n",
    "            path_to_file = os.path.join(\"./exam/image/\"+a)\n",
    "            image=cv2.imread(path_to_file)\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            image_from_array = Image.fromarray(gray)\n",
    "            data.append(np.array(image_from_array))\n",
    "    except AttributeError:\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Exam=np.array(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_exam = Exam.astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing label name\n",
    "label = np.array([\n",
    "    'Lv4',\n",
    "    'Lv3',\n",
    "    'Lv2',\n",
    "    'Lv0',\n",
    "    'Lv1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows, img_cols = 288,432\n",
    "img_channels = 1\n",
    "# Adjustment of input type of dimension number due to difference of backend\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_exam = x_exam.reshape(x_exam.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_exam = x_exam.reshape(x_exam.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictive visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_exam_pred = model_exam.predict(x_exam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1c345fa1d0>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Predictive visualization\n",
    "#Numerals of images passed by Y axis, and X axis is estimated by neural network\n",
    "\n",
    "plt.imshow(Y_exam_pred[:5], cmap='gray', interpolation='nearest', vmin=0, vmax=1)\n",
    "#plt.savefig(\"save.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred: Lv3\n"
     ]
    }
   ],
   "source": [
    "print(\"pred:\",label[np.argmax(Y_exam_pred[0]+Y_exam_pred[1]+Y_exam_pred[2]+Y_exam_pred[3]+Y_exam_pred[4])])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
